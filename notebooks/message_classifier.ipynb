{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "k6fe7rlH3tsn",
    "outputId": "26c9f0dd-a2c3-4592-e9be-91d7bd2647ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                      message_text message_type\n",
       "0                  Hi, I am Sasha         fact\n",
       "1   Where is the nearest library?     question\n",
       "2                         I am 21         fact\n",
       "3            She works in library         fact\n",
       "4        it is quite unbeliavable        trash\n",
       "..                            ...          ...\n",
       "85          nice to meet you too!         fact\n",
       "86                  bad day today         fact\n",
       "87                             Hi         fact\n",
       "88           I found 5 cats today         fact\n",
       "89     How many cats I saw today?     question\n",
       "\n",
       "[90 rows x 2 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/olexandryermilov/deeploma/master/datasets/messages.csv')\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "0PgLUqQFANjs",
    "outputId": "224b982f-e317-490d-931d-b8797435d262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fact', 'question', 'fact', 'fact', 'trash', 'request', 'request',\n",
       "       'question', 'fact', 'trash', 'trash', 'fact', 'trash', 'fact',\n",
       "       'fact', 'question', 'fact', 'fact', 'question', 'question',\n",
       "       'question', 'trash', 'request', 'request', 'request', 'request',\n",
       "       'request', 'request', 'request', 'request', 'request', 'request',\n",
       "       'request', 'request', 'request', 'request', 'request', 'request',\n",
       "       'request', 'request', 'request', 'question', 'trash', 'trash',\n",
       "       'fact', 'fact', 'question', 'request', 'trash', 'trash', 'fact',\n",
       "       'fact', 'fact', 'fact', 'fact', 'question', 'question', 'fact',\n",
       "       'question', 'question', 'fact', 'fact', 'fact', 'fact', 'question',\n",
       "       'fact', 'question', 'question', 'fact', 'question', 'question',\n",
       "       'fact', 'fact', 'fact', 'fact', 'fact', 'fact', 'fact', 'fact',\n",
       "       'fact', 'fact', 'fact', 'fact', 'fact', 'fact', 'fact', 'fact',\n",
       "       'fact', 'fact', 'question'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data['message_text'].values\n",
    "Y_train = data['message_type'].values\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JTv6k_WYIcx1",
    "outputId": "cbfc3996-3135-40c8-ceb3-6ffb19ab308d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oleksandry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.dev.wixpress.com/artifactory/api/pypi/pypi-local/simple, https://pypi.python.org/simple\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x10ea71690>, 'Connection to repo.dev.wixpress.com timed out. (connect timeout=15)')': /artifactory/api/pypi/pypi-local/simple/nltk/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x10ea710d0>, 'Connection to repo.dev.wixpress.com timed out. (connect timeout=15)')': /artifactory/api/pypi/pypi-local/simple/nltk/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x10ea71310>, 'Connection to repo.dev.wixpress.com timed out. (connect timeout=15)')': /artifactory/api/pypi/pypi-local/simple/nltk/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x10eab3f90>, 'Connection to repo.dev.wixpress.com timed out. (connect timeout=15)')': /artifactory/api/pypi/pypi-local/simple/nltk/\u001b[0m\n",
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 580kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/site-packages (from nltk) (0.15.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/site-packages (from nltk) (2020.5.14)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from nltk) (4.46.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-cp37-none-any.whl size=1434674 sha256=5de9c6807f55d4e8dcc0cd4f7647029571db2a4ed54657ce1607d740cda3f3cc\n",
      "  Stored in directory: /Users/oleksandry/Library/Caches/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.5\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJ9ZNez9IWvK"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower()# lowercase text\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE,\" \", text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = re.sub(BAD_SYMBOLS_RE,\"\", text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = re.sub('  ', ' ', text)\n",
    "    text = re.sub('  ', ' ', text)\n",
    "    #text = ' '.join(list(filter(lambda x: x not in STOPWORDS, text.split(\" \")))) # delete stopwords from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhVBp_Y5VIom"
   },
   "outputs": [],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for x in text_prepare(text).split(\" \"):\n",
    "      if(x in words_to_index):\n",
    "        result_vector.itemset(words_to_index[x], 1)\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBhg48bXxsXb"
   },
   "outputs": [],
   "source": [
    "def countQuestions(text):\n",
    "  x = 0\n",
    "  for char in text:\n",
    "    if char == '?':\n",
    "      x = x + 1\n",
    "  return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFmim7FOCrbj"
   },
   "outputs": [],
   "source": [
    "def count_wh_words(text):\n",
    "  x = 0\n",
    "  for word in text_prepare(text).split(' '):\n",
    "    if(word == 'when' or word == 'who' or word == 'why' or word =='whom' or word == 'where'):\n",
    "      x = x + 1\n",
    "  return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6J4kCiWWEC9"
   },
   "outputs": [],
   "source": [
    "words = [x for item in X_train for x in text_prepare(item).split(' ') ]\n",
    "unique, counts = np.unique(words, return_counts=True)\n",
    "words_counts= dict(zip(unique, counts))\n",
    "DICT_SIZE = 5000\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {j:i for i,j in enumerate(words_counts)}\n",
    "INDEX_TO_WORDS = {i:j for i,j in enumerate(words_counts)}\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_d6-AS5mYtrD",
    "outputId": "a156e874-90fb-417e-dcf7-0b14973ed554"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fact', 'question', 'request', 'trash'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_t, counts_t = np.unique([x for x in Y_train], return_counts=True)\n",
    "tags_counts = dict(zip(unique_t, counts_t))\n",
    "tags_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5d9Zptzmzz4d"
   },
   "outputs": [],
   "source": [
    "def prepare_text_for_model(text):\n",
    "  bow = my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)\n",
    "  questions = np.array([countQuestions(text)])\n",
    "  wh_words = np.array([count_wh_words(text)])\n",
    "  return sp_sparse.csr_matrix(np.concatenate((bow, np.concatenate((questions, wh_words)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jhkuAcSyYBgR",
    "outputId": "578e83e5-da2d-4a1d-d196-4b21d30af8a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 5002)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "X_train_mybag = sp_sparse.vstack([prepare_text_for_model(text) for text in X_train])\n",
    "X_train_mybag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVY6uK9cYVa8"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "TAGS_FOR_INDEX = {j:i for i,j in enumerate(tags_counts)}\n",
    "INDEX_TO_TAGS = {i:j for i,j in enumerate(tags_counts)}\n",
    "y_train = [TAGS_FOR_INDEX[x] for x in Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qs9CFlcZNed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111111111111111\n",
      "[[22  0  0  0]\n",
      " [ 2  6  0  0]\n",
      " [ 0  0 13  0]\n",
      " [ 1  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "x_train, x_test, y_train_, y_test = train_test_split(X_train_mybag, y_train, test_size=0.5)\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 4).fit(x_train, y_train_) \n",
    "y_pred = dtree_model.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qk1_ZgvvauZ4",
    "outputId": "6e6b62fb-7df5-400a-f454-ab7426dac4a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_TO_TAGS[dtree_model.predict(prepare_text_for_model('What is a road?'))[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REQUEST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c1db886ed553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#POST /classify_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREQUEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(req)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mINDEX_TO_TAGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_text_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What is a road?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'REQUEST' is not defined"
     ]
    }
   ],
   "source": [
    "#POST /classify_message\n",
    "req = json.loads(REQUEST)['body']\n",
    "#print(req)\n",
    "text = req['text']  \n",
    "print(json.dumps({'answer': INDEX_TO_TAGS[dtree_model.predict(prepare_text_for_model('What is a road?'))[0]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "message_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
