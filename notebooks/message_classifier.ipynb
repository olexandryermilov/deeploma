{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "message_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6fe7rlH3tsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "26c9f0dd-a2c3-4592-e9be-91d7bd2647ba"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/olexandryermilov/deeploma/master/datasets/messages.csv')\n",
        "data.head"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                message_text  message_type\n",
              "0                            Hi, I am Sasha          fact\n",
              "1             Where is the nearest library?      question\n",
              "2                                   I am 21          fact\n",
              "3                      She works in library          fact\n",
              "4                  it is quite unbeliavable         trash\n",
              "5             book me a table in restaurant       request\n",
              "6   remind me to drink water in few minutes       request\n",
              "7             how to get to the city centre      question\n",
              "8                       i come from ukraine          fact\n",
              "9                                  ho ho ho         trash\n",
              "10                                    hello         trash\n",
              "11                          my name is Kate          fact\n",
              "12                             good morning         trash\n",
              "13                          she is not here          fact\n",
              "14                         my hair is white          fact\n",
              "15                    when is your birthday      question\n",
              "16           i was 21 when i wrote this bot          fact\n",
              "17           when i wrote this bot i was 21          fact\n",
              "18         when will the quarantine be over      question\n",
              "19                   how long is this film?      question\n",
              "20                     what day is it today      question\n",
              "21         what is love, baby dont hurt me\"         trash>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PgLUqQFANjs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "224b982f-e317-490d-931d-b8797435d262"
      },
      "source": [
        "X_train = data['message_text'].values\n",
        "Y_train = data['message_type'].values\n",
        "Y_train"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fact', ' question', ' fact', ' fact', ' trash', ' request',\n",
              "       ' request', ' question', ' fact', ' trash', ' trash', ' fact',\n",
              "       ' trash', ' fact', ' fact', ' question', ' fact', ' fact',\n",
              "       ' question', ' question', ' question', ' trash'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTv6k_WYIcx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cbfc3996-3135-40c8-ceb3-6ffb19ab308d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ9ZNez9IWvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def text_prepare(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower()# lowercase text\n",
        "    text = re.sub(REPLACE_BY_SPACE_RE,\" \", text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = re.sub(BAD_SYMBOLS_RE,\"\", text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = re.sub('  ', ' ', text)\n",
        "    text = re.sub('  ', ' ', text)\n",
        "    #text = ' '.join(list(filter(lambda x: x not in STOPWORDS, text.split(\" \")))) # delete stopwords from text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhVBp_Y5VIom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_bag_of_words(text, words_to_index, dict_size):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        dict_size: size of the dictionary\n",
        "        \n",
        "        return a vector which is a bag-of-words representation of 'text'\n",
        "    \"\"\"\n",
        "    result_vector = np.zeros(dict_size)\n",
        "    for x in text_prepare(text).split(\" \"):\n",
        "      if(x in words_to_index):\n",
        "        result_vector.itemset(words_to_index[x], 1)\n",
        "    return result_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBhg48bXxsXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def countQuestions(text):\n",
        "  x = 0\n",
        "  for char in text:\n",
        "    if char == '?':\n",
        "      x = x + 1\n",
        "  return x    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFmim7FOCrbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_wh_words(text):\n",
        "  x = 0\n",
        "  for word in text_prepare(text).split(' '):\n",
        "    if(word == 'when' or word == 'who' or word == 'why' or word =='whom' or word == 'where'):\n",
        "      x = x + 1\n",
        "  return x     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6J4kCiWWEC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = [x for item in X_train for x in text_prepare(item).split(' ') ]\n",
        "unique, counts = np.unique(words, return_counts=True)\n",
        "words_counts= dict(zip(unique, counts))\n",
        "DICT_SIZE = 5000\n",
        "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:DICT_SIZE]\n",
        "WORDS_TO_INDEX = {j:i for i,j in enumerate(words_counts)}\n",
        "INDEX_TO_WORDS = {i:j for i,j in enumerate(words_counts)}\n",
        "ALL_WORDS = WORDS_TO_INDEX.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d6-AS5mYtrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a156e874-90fb-417e-dcf7-0b14973ed554"
      },
      "source": [
        "unique_t, counts_t = np.unique([x for x in Y_train], return_counts=True)\n",
        "tags_counts = dict(zip(unique_t, counts_t))\n",
        "tags_counts.keys()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([' fact', ' question', ' request', ' trash'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d9Zptzmzz4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_text_for_model(text):\n",
        "  bow = my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)\n",
        "  questions = np.array([countQuestions(text)])\n",
        "  wh_words = np.array([count_wh_words(text)])\n",
        "  return sp_sparse.csr_matrix(np.concatenate((bow, np.concatenate((questions, wh_words)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhkuAcSyYBgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "578e83e5-da2d-4a1d-d196-4b21d30af8a6"
      },
      "source": [
        "from scipy import sparse as sp_sparse\n",
        "X_train_mybag = sp_sparse.vstack([prepare_text_for_model(text) for text in X_train])\n",
        "X_train_mybag.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape  (22, 5002)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVY6uK9cYVa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
        "TAGS_FOR_INDEX = {j:i for i,j in enumerate(tags_counts)}\n",
        "INDEX_TO_TAGS = {i:j for i,j in enumerate(tags_counts)}\n",
        "y_train = [TAGS_FOR_INDEX[x] for x in Y_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qs9CFlcZNed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train_mybag, y_train) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk1_ZgvvauZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e6b62fb-7df5-400a-f454-ab7426dac4a0"
      },
      "source": [
        "INDEX_TO_TAGS[dtree_model.predict(prepare_text_for_model('Hi, I am 2304123'))[0]]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' fact'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}